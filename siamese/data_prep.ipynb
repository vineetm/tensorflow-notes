{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we do some basic pre-processing to [Ubuntu Dialogue Corpus v2](https://github.com/rkadlec/ubuntu-ranking-dataset-creator). \n",
    "* Download tokenized and lower cased data\n",
    "* Separate training csv file into `context`, `response` and `flag` files\n",
    "* Sample validation file to have same distribution as training data: 1 positive and 1 negative\n",
    "* Build a vocabulary file from training data. Only keep words that appear atleast 50 times. Also add UNK token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P0: Download Data\n",
    "\n",
    "We will work with [Ubuntu Dialogue Corpus v2](https://github.com/rkadlec/ubuntu-ranking-dataset-creator). \n",
    "\n",
    "[Petr Baudi≈°](https://github.com/pasky) has [kindly pre-processed and made available a tokenized version](https://github.com/brmson/dataset-sts/tree/master/data/anssel/ubuntu) of this corpus, and we will work with that!\n",
    "\n",
    "We will lowercase the data though.\n",
    "\n",
    "It might be a good idea to create a data directory (Let's call it `ubuntu-data`) and put all these files inside it.\n",
    "Be careful, as this would donwnload three files of total size `196 MB`. On unzipping, this would take a space of `734 MB` so make sure you have that much free space (and bandwidth available)!\n",
    "\n",
    "Open your bash terminal and download and unzip the data as follows:\n",
    "\n",
    "```bash\n",
    "    mkdir ubuntu-data\n",
    "    cd ubuntu-data\n",
    "    \n",
    "    wget http://rover.ms.mff.cuni.cz/~pasky/ubuntu-dialog/v2-trainset.csv.gz\n",
    "    wget http://rover.ms.mff.cuni.cz/~pasky/ubuntu-dialog/v2-valset.csv.gz\n",
    "    wget http://rover.ms.mff.cuni.cz/~pasky/ubuntu-dialog/v2-testset.csv.gz\n",
    "    gunzip v2*.gz\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P1: Take a peek!\n",
    "The first thing you should do after downloading text data is to count number of lines in it, and have a peek at it ;) \n",
    "\n",
    "My favorite tools for counting is unix tool `wc` and for peeking `head`\n",
    "\n",
    "```bash\n",
    "\n",
    "wc -l *.csv\n",
    "```\n",
    "\n",
    "You should see something like this:\n",
    "\n",
    "```bash\n",
    "  189200 v2-testset.csv\n",
    " 1000000 v2-trainset.csv\n",
    "  195600 v2-valset.csv\n",
    " 1384800 total\n",
    "```\n",
    "\n",
    "Okay, so we have `1M` lines in training csv, about `195K` in validation and `189K` in test.\n",
    "\n",
    "Now let us have a peek at train file `v2-trainset.csv`.\n",
    "\n",
    "```bash\n",
    "head -1 v2-trainset.csv\n",
    "```\n",
    "\n",
    "I am not going to put the output returned here, as it will fill this notebook ;). But you would notice that the line has three parts: two sentences and a label. First sentence is the `context`. Second sentence is the `response`. Last part is the `flag`, which specifies if the response is correct.\n",
    "\n",
    "Also, notice that each sentence has some special tokens\n",
    "* End of utterance `__eou__`\n",
    "* End of Turn `__eot__`\n",
    "\n",
    "* Think of each sentence as a list of turns (User1 followed by User2). Each turn is in turn a list of utterances (from a single user)\n",
    "\n",
    "For example, the sentence `i agree that we should kill the -novtswitch __eou__ __eot__ ok __eou__ __eot` should be understood as\n",
    "```\n",
    "User1: i agree that we should kill the -novtswitch\n",
    "User2: ok\n",
    "```\n",
    "\n",
    "How about validation and test files? \n",
    "```bash\n",
    "head -20 head v2-valset.csv\n",
    "```\n",
    "You would notice that the first sentence (`context`) is same for 10 sentences, and 9 sentences in 10 have label 0 and 1 sentence label 0. This dataset is designed to select correct response from 10."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P2: Separate `v2-trainset.csv` into Context, Response and Flag\n",
    "\n",
    "I still have not yet figured out how to separate CSV data directly using dataset API. I probably need to [read this more carefully](https://github.com/tensorflow/tensorflow/blob/r1.4/tensorflow/examples/get_started/regression/imports85.py)!\n",
    "\n",
    "I do however, understand how [`TextLineDataset`](https://www.tensorflow.org/versions/master/api_docs/python/tf/data/TextLineDataset) works when each line in text is a single sentence. Thus, in this section, we will separate out CSV to three different files: `train.context`, `train.response` and `train.flag` using plain old python! Probably an overkill, but we ought to make progress! :)\n",
    "\n",
    "These three new files (`train.context`, `train.response` and `train.flag`) are definitely `TextLineDataset` friendly. Don't worry too much now, we will see how in much more detail than you like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, csv\n",
    "import numpy as np\n",
    "\n",
    "#Set this to actual path of the folder where your CSV files reside.\n",
    "DATA_DIR = 'ubuntu-data'\n",
    "\n",
    "train_csv_file = os.path.join(DATA_DIR, 'v2-trainset.csv')\n",
    "train_context_file = os.path.join(DATA_DIR, 'train.context')\n",
    "train_response_file = os.path.join(DATA_DIR, 'train.response')\n",
    "train_flag_file = os.path.join(DATA_DIR, 'train.flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num rows in Train csv: 1000000\n"
     ]
    }
   ],
   "source": [
    "fw_train_context = open(train_context_file, 'w')\n",
    "fw_train_response = open(train_response_file, 'w')\n",
    "fw_train_flag = open(train_flag_file, 'w')\n",
    "    \n",
    "num_rows = 0\n",
    "\n",
    "with open(train_csv_file) as fr:\n",
    "    reader = csv.reader(fr)\n",
    "    for row in reader:\n",
    "        assert len(row) == 3\n",
    "        fw_train_context.write('%s\\n'%row[0].strip().lower())\n",
    "        fw_train_response.write('%s\\n'%row[1].strip().lower())\n",
    "        fw_train_flag.write('%s\\n'%row[2].strip())\n",
    "        num_rows += 1\n",
    "print('Num rows in Train csv: {}'.format(num_rows))       \n",
    "\n",
    "#Important, we do need to close the files, before using them.\n",
    "fw_train_context.close()\n",
    "fw_train_response.close()\n",
    "fw_train_flag.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we should now have three new files in `ubuntu-data`. What do we do when we get text data? \n",
    "\n",
    "Count lines and take a peek to ensure everything looks good! \n",
    "\n",
    "* Check that number of lines is `1M` in all the files\n",
    "    ```bash\n",
    "    wc -l train.*\n",
    "    ```\n",
    "    \n",
    "* Check first and last line of `v2-trainset.csv`. Does this match your new files? `train.context`, `train.response` and `train.flag`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P3: sample `v2-valset.csv`\n",
    "We saw in P1 that validation and test CSV files have 9 negative flags and 1 positive flags. \n",
    "\n",
    "Let us see what is the dsitribution of negative flags for training data. \n",
    "\n",
    "All we need to do is to count `0` in the new file we created in P2 `train.flag`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train neg_labels: 500127\n"
     ]
    }
   ],
   "source": [
    "num_neg = 0\n",
    "with open(train_flag_file) as fr:\n",
    "    for line in fr:\n",
    "        line = line.strip()\n",
    "        if line == '0':\n",
    "            num_neg += 1\n",
    "print('Train neg_labels: {}'.format(num_neg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so it seems the negative and positive labels are *almost* equally distributed.\n",
    "\n",
    "The validation and test files however, do not have the same distribution. In order to check if our text correlation model has been trained well, we would like to compare loss on training and validation set. This would only be comparable if they *atleast* have similar distribution of labels!\n",
    "\n",
    "Thus, here we would **sample** `v2-valset.csv`. We will randomly select 1 negative response out of 9. And ofcourse, keep the positive response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Paths for validation file\n",
    "valid_csv_file = os.path.join(DATA_DIR, 'v2-valset.csv')\n",
    "\n",
    "valid_context_file = os.path.join(DATA_DIR, 'valid.context')\n",
    "valid_response_file = os.path.join(DATA_DIR, 'valid.response')\n",
    "valid_flag_file = os.path.join(DATA_DIR, 'valid.flag')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#If you look closely at v2-valset.csv, you will see that the first example out of 10 always has `flag=1`\n",
    "fw_valid_context = open(valid_context_file, 'w')\n",
    "fw_valid_response = open(valid_response_file, 'w')\n",
    "fw_valid_flag = open(valid_flag_file, 'w')\n",
    "\n",
    "#Fixed random seed for reproducibility\n",
    "np.random.seed(1543)\n",
    "\n",
    "sample_num = 0\n",
    "neg_responses = []\n",
    "pos_response = None\n",
    "context = None\n",
    "with open(valid_csv_file) as fr:\n",
    "    reader = csv.reader(fr)\n",
    "    for row in reader:\n",
    "        if sample_num == 0:\n",
    "            context = row[0].strip().lower()\n",
    "            pos_response = row[1].strip().lower()\n",
    "        else:\n",
    "            neg_responses.append(row[1].strip().lower())\n",
    "        sample_num += 1\n",
    "\n",
    "        #We \n",
    "        if sample_num == 10:\n",
    "            random_int = np.random.randint(9)\n",
    "            #Write positive data\n",
    "            fw_valid_context.write('%s\\n'%context)\n",
    "            fw_valid_response.write('%s\\n'%pos_response)\n",
    "            fw_valid_flag.write('%d\\n'%1)\n",
    "            \n",
    "            #Write negative data\n",
    "            fw_valid_context.write('%s\\n'%context)\n",
    "            fw_valid_response.write('%s\\n'%neg_responses[random_int])\n",
    "            fw_valid_flag.write('%d\\n'%0)\n",
    "\n",
    "            neg_responses = []\n",
    "            sample_num = 0\n",
    "            \n",
    "    assert not neg_responses\n",
    "\n",
    "# Again, this step is important when writing to files within a notebook!\n",
    "fw_valid_context.close()\n",
    "fw_valid_response.close()\n",
    "fw_valid_flag.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now have new validation files.`valid.context`,  `valid.response` and `valid.flag`\n",
    "\n",
    "As always, verify number of lines and do a peek! \n",
    "\n",
    "You should find number of lines to be `19560 * 2 = 39120`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### P4: Vocab file\n",
    "\n",
    "Okay, so we are done with separating our data.\n",
    "\n",
    "Now, we are finally left with creating a vocab file. We will use [`Counter`](https://docs.python.org/3/library/collections.html#collections.Counter) to count words, and only retain words that appear atleast 50 times. You can experiment with a higher minimum frequency. \n",
    "\n",
    "We will also add a special symbol `UNK` which will refer to all out of vocabulary words. We will **only** use training file to build the vocabulary.\n",
    "\n",
    "Let us begin!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index: 59414 Vocab: 96881\n",
      "Index: 119609 Vocab: 153941\n",
      "Index: 178763 Vocab: 203333\n",
      "Index: 236851 Vocab: 249512\n",
      "Index: 294173 Vocab: 292395\n",
      "Index: 352036 Vocab: 332966\n",
      "Index: 409958 Vocab: 372606\n",
      "Index: 468534 Vocab: 411856\n",
      "Index: 526642 Vocab: 451210\n",
      "Index: 584394 Vocab: 489346\n",
      "Index: 641870 Vocab: 527417\n",
      "Index: 699277 Vocab: 566036\n",
      "Index: 755791 Vocab: 603585\n",
      "Index: 812726 Vocab: 641210\n",
      "Index: 870317 Vocab: 678494\n",
      "Index: 928442 Vocab: 700066\n",
      "Index: 988980 Vocab: 705089\n",
      "Final Vocab: 706028\n",
      "[('__eou__', 12445416), ('__eot__', 7908302), ('i', 5435158), ('the', 4550778), (',', 4294744), ('to', 3902622), ('?', 3749674), ('.', 3462904), ('it', 3251880), ('a', 2699816)]\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "words = []\n",
    "counter = Counter()\n",
    "\n",
    "for index, (context, response) in enumerate(zip(open(train_context_file), open(train_response_file))):\n",
    "    words.extend(context.split())\n",
    "    words.extend(context.split())\n",
    "    \n",
    "    #This is to keep memory foot print low\n",
    "    #If we get 10M words we update counter\n",
    "    if len(words) > 10000000:\n",
    "        counter.update(words)\n",
    "        print ('Index: {} Vocab: {}'.format(index, len(counter)))\n",
    "        words = []\n",
    "        \n",
    "#Final update\n",
    "if words:\n",
    "    counter.update(words)\n",
    "    print ('Final Vocab: {}'.format(len(counter)))\n",
    "    words = []\n",
    "\n",
    "print(counter.most_common(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that seems fine. Top 10 words have eou eot and other common words in English.\n",
    "\n",
    "Now, we just need to write the words to our vocab file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_vocab(fw, counter, min_freq=50):\n",
    "    fw.write('%s\\n'%'UNK')\n",
    "    for w, f in counter.most_common():\n",
    "        if f < min_freq:\n",
    "            return\n",
    "        fw.write('%s\\n'%w)\n",
    "\n",
    "vocab_file = os.path.join(DATA_DIR, 'vocab.txt')       \n",
    "with open(vocab_file, 'w') as fw:\n",
    "    write_vocab(fw, counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As always, let us have a look at our vocab file. Count number of lines. See top words, to make sure everything looks OK!\n",
    "```bash\n",
    "head vocab.txt\n",
    "```\n",
    "\n",
    "```bash\n",
    "UNK\n",
    "__eou__\n",
    "__eot__\n",
    "i\n",
    "the\n",
    ",\n",
    "to\n",
    "?\n",
    ".\n",
    "it\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
